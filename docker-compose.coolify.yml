version: '3.8'

# Coolify-Optimized Docker Compose for Interactive World News Map
# This configuration uses pre-built images and can be deployed directly in Coolify
# without cloning the repository

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-news_map_db}
      POSTGRES_USER: ${POSTGRES_USER:-news_map_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256 --auth-local=scram-sha-256"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - news-map-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-news_map_user} -d ${POSTGRES_DB:-news_map_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Redis Cache
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes --appendfsync everysec
    volumes:
      - redis_data:/data
    networks:
      - news-map-network
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Backend API (Pre-built image from GitHub Container Registry)
  backend:
    image: ghcr.io/kingkhan92/world-news-map-backend:latest
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3001
      DATABASE_URL: postgresql://${POSTGRES_USER:-news_map_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-news_map_db}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN:-24h}
      NEWS_API_KEY: ${NEWS_API_KEY}
      GUARDIAN_API_KEY: ${GUARDIAN_API_KEY}
      GEOCODING_API_KEY: ${GEOCODING_API_KEY}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      CORS_ORIGIN: ${CORS_ORIGIN:-*}
      RATE_LIMIT_WINDOW_MS: ${RATE_LIMIT_WINDOW_MS:-900000}
      RATE_LIMIT_MAX_REQUESTS: ${RATE_LIMIT_MAX_REQUESTS:-100}
      RUN_MIGRATIONS: "true"
      # LLM Provider Configuration
      BIAS_ANALYSIS_PROVIDER: ${BIAS_ANALYSIS_PROVIDER:-openai}
      BIAS_ANALYSIS_FALLBACK_PROVIDERS: ${BIAS_ANALYSIS_FALLBACK_PROVIDERS:-openai}
      # OpenAI Configuration
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-3.5-turbo}
      OPENAI_BASE_URL: ${OPENAI_BASE_URL:-https://api.openai.com/v1}
      OPENAI_TIMEOUT: ${OPENAI_TIMEOUT:-30000}
      OPENAI_MAX_RETRIES: ${OPENAI_MAX_RETRIES:-3}
      OPENAI_RATE_LIMIT: ${OPENAI_RATE_LIMIT:-60}
      # Grok Configuration (Optional)
      GROK_API_KEY: ${GROK_API_KEY}
      GROK_MODEL: ${GROK_MODEL:-grok-beta}
      GROK_BASE_URL: ${GROK_BASE_URL:-https://api.x.ai/v1}
      GROK_TIMEOUT: ${GROK_TIMEOUT:-30000}
      GROK_MAX_RETRIES: ${GROK_MAX_RETRIES:-3}
      GROK_RATE_LIMIT: ${GROK_RATE_LIMIT:-60}
      # External Ollama Configuration (Optional)
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama2:7b}
      OLLAMA_TIMEOUT: ${OLLAMA_TIMEOUT:-60000}
      OLLAMA_MAX_RETRIES: ${OLLAMA_MAX_RETRIES:-2}
      OLLAMA_RATE_LIMIT: ${OLLAMA_RATE_LIMIT:-30}
      # LLM Health Check Configuration
      LLM_HEALTH_CHECK_INTERVAL: ${LLM_HEALTH_CHECK_INTERVAL:-300000}
      LLM_ENABLE_FAILOVER: ${LLM_ENABLE_FAILOVER:-true}
    volumes:
      - backend_logs:/app/logs
    networks:
      - news-map-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Frontend React App (Pre-built image from GitHub Container Registry)
  frontend:
    image: ghcr.io/kingkhan92/world-news-map-frontend:latest
    restart: unless-stopped
    environment:
      VITE_API_URL: ${VITE_API_URL:-http://localhost:3001}
      VITE_SOCKET_URL: ${VITE_SOCKET_URL:-http://localhost:3001}
    networks:
      - news-map-network
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # NGINX Reverse Proxy (Optional - Coolify can handle this)
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    volumes:
      - nginx_cache:/var/cache/nginx
      - nginx_logs:/var/log/nginx
    networks:
      - news-map-network
    depends_on:
      frontend:
        condition: service_healthy
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
    # Custom nginx config for Coolify
    command: |
      sh -c "
      cat > /etc/nginx/nginx.conf << 'EOF'
      events {
          worker_connections 1024;
      }
      http {
          upstream backend {
              server backend:3001;
          }
          upstream frontend {
              server frontend:3000;
          }
          server {
              listen 80;
              location /api/ {
                  proxy_pass http://backend;
                  proxy_set_header Host \$$host;
                  proxy_set_header X-Real-IP \$$remote_addr;
                  proxy_set_header X-Forwarded-For \$$proxy_add_x_forwarded_for;
                  proxy_set_header X-Forwarded-Proto \$$scheme;
              }
              location /socket.io/ {
                  proxy_pass http://backend;
                  proxy_http_version 1.1;
                  proxy_set_header Upgrade \$$http_upgrade;
                  proxy_set_header Connection 'upgrade';
                  proxy_set_header Host \$$host;
                  proxy_cache_bypass \$$http_upgrade;
              }
              location /health {
                  return 200 'OK';
                  add_header Content-Type text/plain;
              }
              location / {
                  proxy_pass http://frontend;
                  proxy_set_header Host \$$host;
                  proxy_set_header X-Real-IP \$$remote_addr;
                  proxy_set_header X-Forwarded-For \$$proxy_add_x_forwarded_for;
                  proxy_set_header X-Forwarded-Proto \$$scheme;
              }
          }
      }
      EOF
      nginx -g 'daemon off;'
      "

networks:
  news-map-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  backend_logs:
    driver: local
  nginx_cache:
    driver: local
  nginx_logs:
    driver: local